{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df169d8-4c37-4450-97b5-6cc781a2ae4a",
   "metadata": {},
   "source": [
    "# DEEE725 Speech Signal Processing Lab\n",
    "### 2023 Spring, Kyungpook National University \n",
    "### Instructor: Gil-Jin Jang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09645527-0887-405f-9a9a-05da9cb45270",
   "metadata": {},
   "source": [
    "## Lab 01 Korean digit recognition using python-hmmlearn\n",
    "version 2, 2023/03/24\n",
    "source: [jayaram1125's github repository](https://github.com/jayaram1125/Single-Word-Speech-Recognition-using-GMM-HMM-)\n",
    "\n",
    "__update description:__\n",
    "\n",
    "1. assigns sound files 8 and 9 for test out of 0...9, the rest (0...7) are for training\n",
    "    no random selection for reproducibility\n",
    "2. folder structure change\n",
    "\n",
    "> segmented/${username}/${dnum}/kdigits${trial}-${dnum}.wav\n",
    "> > for example, for user \"gjang\", digit 2, recording trial 0 (1st)\n",
    "> > \"segmented/gjang/2/kdigits0-2.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc2499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (0.10.0.post2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (0.3.4)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.3)\n",
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.2.8-cp39-cp39-win_amd64.whl (110 kB)\n",
      "     -------------------------------------- 110.1/110.1 kB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from hmmlearn) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from hmmlearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from hmmlearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from scikit-learn>=0.16->hmmlearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\it2-000\\anaconda3\\lib\\site-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fbc717-5dc6-43a9-b7c3-9f8f2b06506f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scikits.talkbox.features import mfcc\n",
    "#librosa.feature.mfcc(*, y=None, sr=22050, S=None, n_mfcc=20, dct_type=2, norm='ortho', lifter=0, **kwargs)[source]\n",
    "from librosa.feature import mfcc\n",
    "from scipy.io import wavfile\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import scipy.stats as sp\n",
    "from time import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371acf2d-ddbd-411e-8134-1a44abcb4593",
   "metadata": {},
   "source": [
    "__hyperparameters__ - CHANGE THEM TO IMPROVE PERFORMANCE\n",
    "1. number of MFCC (feature dimension), try `num_mfcc` 6, 10, 13\n",
    "\n",
    "2. Parameters needed to train GMMHMM: number of HMM states, number of Gaussian mixtures, diagonal or full covariance matrix, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5764004d-1445-4762-9e67-a1cb8744faa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. number of MFCC (feature dimension)\n",
    "num_mfcc = 6\n",
    "#num_mfcc = 10\n",
    "#num_mfcc = 13\n",
    "# 2. Parameters needed to train GMMHMM\n",
    "m_num_of_HMMStates = 3  # number of states\n",
    "m_num_of_mixtures = 2  # number of mixtures for each hidden state\n",
    "m_covarianceType = 'diag'  # covariance type\n",
    "m_n_iter = 10  # number of iterations\n",
    "m_bakisLevel = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0a7b0e8-fd5c-4e48-8a1b-ef1b71ae8115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract MFCC features\n",
    "def extmfcc(file):\n",
    "    samplerate, d = wavfile.read(file)\n",
    "    #features.append(mfcc(d, nwin=int(samplerate * 0.03), fs=samplerate, nceps= 6)[0])\n",
    "    x = np.float32(d)\n",
    "    hop=samplerate//100\n",
    "    mc = mfcc(y=x, sr=samplerate, n_mfcc=num_mfcc, hop_length=hop, win_length=hop*2)\n",
    "    return np.transpose(mc, (1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bc3d0-d556-40d1-b2af-46076a7431b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "__load data files__\n",
    "\n",
    "1. find files: \n",
    "    for user `\"gjang\"`, digit 2, recording trial 0 (1st)\n",
    "    `\"segmented/gjang/2/kdigits0-2.wav\"`\n",
    "2. extract MFCC features for training and testing\n",
    "    for each digit, indexes 4 and 9 for test, and the rest for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5369c97e-f05f-4853-9cf4-5a6a7235773f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmented/deokkyukwon/0/kdigits0-0.wav 0 (28, 6) training\n",
      "segmented/deokkyukwon/0/kdigits1-0.wav 0 (26, 6) training\n",
      "segmented/deokkyukwon/0/kdigits2-0.wav 0 (39, 6) training\n",
      "segmented/deokkyukwon/0/kdigits3-0.wav 0 (38, 6) training\n",
      "segmented/deokkyukwon/0/kdigits4-0.wav 0 (37, 6) testing\n",
      "segmented/deokkyukwon/0/kdigits5-0.wav 0 (24, 6) training\n",
      "segmented/deokkyukwon/0/kdigits6-0.wav 0 (29, 6) training\n",
      "segmented/deokkyukwon/0/kdigits7-0.wav 0 (27, 6) training\n",
      "segmented/deokkyukwon/0/kdigits8-0.wav 0 (31, 6) training\n",
      "segmented/deokkyukwon/0/kdigits9-0.wav 0 (33, 6) testing\n",
      "segmented/deokkyukwon/1/kdigits0-1.wav 1 (42, 6) training\n",
      "segmented/deokkyukwon/1/kdigits1-1.wav 1 (35, 6) training\n",
      "segmented/deokkyukwon/1/kdigits2-1.wav 1 (46, 6) training\n",
      "segmented/deokkyukwon/1/kdigits3-1.wav 1 (30, 6) training\n",
      "segmented/deokkyukwon/1/kdigits4-1.wav 1 (43, 6) testing\n",
      "segmented/deokkyukwon/1/kdigits5-1.wav 1 (41, 6) training\n",
      "segmented/deokkyukwon/1/kdigits6-1.wav 1 (42, 6) training\n",
      "segmented/deokkyukwon/1/kdigits7-1.wav 1 (35, 6) training\n",
      "segmented/deokkyukwon/1/kdigits8-1.wav 1 (26, 6) training\n",
      "segmented/deokkyukwon/1/kdigits9-1.wav 1 (40, 6) testing\n",
      "...\n",
      "\n",
      "Words spoken: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "#fpaths = []\n",
    "#labels = []\n",
    "spoken = []\n",
    "m_trainingsetfeatures = []\n",
    "m_trainingsetlabels = []\n",
    "m_testingsetfeatures = []\n",
    "m_testingsetlabels = []\n",
    "n_folds = 5   # 0...3 for training, 4 for testing\n",
    "\n",
    "apath = 'segmented'\n",
    "count = 0\n",
    "for username in os.listdir(apath):\n",
    "    apath2 = apath + '/' + username    # example: segmented/gjang\n",
    "    for ii in range(10):   #dnum in os.listdir(apath2):\n",
    "        dnum = str(ii)\n",
    "        apath3 = apath2 + '/' + dnum     # example: segmented/gjang/2\n",
    "        if dnum not in spoken:\n",
    "            spoken.append(dnum)\n",
    "        for trial in range(10):\n",
    "            file = apath3 + '/' + \"kdigits{}-{}.wav\".format(trial,dnum)      # segmented/gjang/2/kdigits0-2.wav\n",
    "            mc = extmfcc(file)\n",
    "\n",
    "            # display file names for the first 20 files only\n",
    "            count += 1\n",
    "            if count <= 20:\n",
    "                print(file, dnum, end=' '); print(mc.shape, end=' ')\n",
    "            elif count == 21:\n",
    "                print('...'); print('')\n",
    "\n",
    "            # 0...3 for training, 4 for testing\n",
    "            if trial % n_folds == (n_folds-1):\n",
    "                if count <= 20: print('testing')\n",
    "                m_testingsetfeatures.append(mc)\n",
    "                m_testingsetlabels.append(dnum)\n",
    "            else:\n",
    "                if count <= 20: print('training')\n",
    "                m_trainingsetfeatures.append(mc)\n",
    "                m_trainingsetlabels.append(dnum)\n",
    "\n",
    "\n",
    "print('Words spoken:', spoken)\n",
    "#print(\"number of labels and features = %d, %d\" % ( len(labels), len(features) ))\n",
    "#print(\"feature shape = \", end='')\n",
    "#print(features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e1ff46-b49e-406f-bf74-907e128edd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gjang: shuffling the data (x)\n",
    "# c = list(zip(features, labels))\n",
    "# np.random.shuffle(c)\n",
    "# features,labels = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2ace1d5-9d79-4e98-8107-afabfc1660d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training] number of labels and features = 80, 80\n",
      "[test] number of labels and features = 20, 20\n",
      "Loading data completed\n"
     ]
    }
   ],
   "source": [
    "# test and training for 100 files\n",
    "ntest  = len(m_testingsetlabels)\n",
    "ntrain = len(m_trainingsetlabels)\n",
    "nfiles = ntest + ntrain\n",
    "\n",
    "print(\"[training] number of labels and features = %d, %d\" % \n",
    "        ( len(m_trainingsetlabels), len(m_trainingsetfeatures)) )\n",
    "print(\"[test] number of labels and features = %d, %d\" % \n",
    "        ( len(m_testingsetlabels), len(m_testingsetfeatures)) )\n",
    "\n",
    "print ('Loading data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8e0b11b-70b4-453a-a631-23f4df66e346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartProbPrior=\n",
      "[1. 0. 0.]\n",
      "TransMatPrior=\n",
      "[[0.5 0.5 0. ]\n",
      " [0.  0.5 0.5]\n",
      " [0.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "gmmhmmindexdict = {}\n",
    "index = 0\n",
    "for word in spoken:\n",
    "    gmmhmmindexdict[word] = index\n",
    "    index = index +1\n",
    "\n",
    "def initByBakis(inumstates, ibakisLevel):\n",
    "    startprobPrior = np.zeros(inumstates)\n",
    "    startprobPrior[0: ibakisLevel - 1] = 1/float((ibakisLevel - 1))\n",
    "    transmatPrior = getTransmatPrior(inumstates, ibakisLevel)\n",
    "    return startprobPrior, transmatPrior\n",
    "\n",
    "def getTransmatPrior(inumstates, ibakisLevel):\n",
    "    transmatPrior = (1 / float(ibakisLevel)) * np.eye(inumstates)\n",
    "\n",
    "    for i in range(inumstates - (ibakisLevel - 1)):\n",
    "        for j in range(ibakisLevel - 1):\n",
    "            transmatPrior[i, i + j + 1] = 1. / ibakisLevel\n",
    "\n",
    "    for i in range(inumstates - ibakisLevel + 1, inumstates):\n",
    "        for j in range(inumstates - i - j):\n",
    "            transmatPrior[i, i + j] = 1. / (inumstates - i)\n",
    "\n",
    "    return transmatPrior\n",
    "\n",
    "m_startprobPrior ,m_transmatPrior = initByBakis(m_num_of_HMMStates,m_bakisLevel)\n",
    "\n",
    "print(\"StartProbPrior=\")\n",
    "print(m_startprobPrior)\n",
    "\n",
    "print(\"TransMatPrior=\")\n",
    "print(m_transmatPrior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfe7d4a7-9011-46f7-8798-8c6010b99e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# acoustic model definition\n",
    "class SpeechModel:\n",
    "    def __init__(self,Class,label):\n",
    "        self.traindata = np.zeros((0,num_mfcc))\n",
    "        self.Class = Class\n",
    "        self.label = label\n",
    "        self.model  = hmm.GMMHMM(n_components = m_num_of_HMMStates, n_mix = m_num_of_mixtures, \\\n",
    "                transmat_prior = m_transmatPrior, startprob_prior = m_startprobPrior, \\\n",
    "                covariance_type = m_covarianceType, n_iter = m_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "851705fb-4910-4f3d-a8a2-e3b2ab26d1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed -- 10 GMM-HMM models are built for 10 different types of words\n",
      "time elapsed: 1.60 seconds\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# training GMMHMM Models \n",
    "start = time()\n",
    "\n",
    "speechmodels = [None] * len(spoken)\n",
    "for key in gmmhmmindexdict:\n",
    "    speechmodels[gmmhmmindexdict[key]] = SpeechModel(gmmhmmindexdict[key],key)\n",
    "\n",
    "for i in range(0,len(m_trainingsetfeatures)):\n",
    "     for j in range(0,len(speechmodels)):\n",
    "         if int(speechmodels[j].Class) == int(gmmhmmindexdict[m_trainingsetlabels[i]]):\n",
    "            speechmodels[j].traindata = np.concatenate((speechmodels[j].traindata , m_trainingsetfeatures[i]))\n",
    "\n",
    "for speechmodel in speechmodels:\n",
    "    speechmodel.model.fit(speechmodel.traindata)\n",
    "\n",
    "print ('Training completed -- {0} GMM-HMM models are built for {0} different types of words'.format(len(spoken)))\n",
    "print('time elapsed: %.2f seconds' % ( time() - start ))\n",
    "print (\" \"); print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75739c76-9c05-4210-8e96-282dadd036e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started\n",
      "[-1013.845 -1650.752 -1244.184 -1159.703 -1170.113 -1320.368 -1089.595\n",
      " -1081.473 -1012.062 -1613.073] -1012.062 :8\n",
      "[ -898.474 -1535.013 -1067.602 -1091.171 -1078.507 -1164.176 -1000.173\n",
      "  -990.207  -939.912 -1450.546] -898.474 :0\n",
      "[-1739.05  -1064.112 -1599.904 -1539.339 -1963.034 -1155.689 -1196.41\n",
      " -1485.434 -1456.624 -1215.284] -1064.112 :1\n",
      "[-1760.859 -1133.983 -1528.318 -1560.974 -2145.242 -1177.463 -1185.216\n",
      " -1706.574 -1600.604 -1284.03 ] -1133.983 :1\n",
      "[-1031.258 -1390.329  -922.507 -1018.829 -1164.36  -1084.701  -986.963\n",
      "  -995.935  -952.857 -1423.447] -922.507 :2\n",
      "[-1425.253 -1967.236 -1159.471 -1542.467 -1780.803 -1474.596 -1337.211\n",
      " -1493.621 -1330.411 -1879.173] -1159.471 :2\n",
      "[-735.293 -898.693 -729.815 -605.07  -737.917 -690.665 -637.944 -702.311\n",
      " -649.195 -888.508] -605.07 :3\n",
      "[-1092.775 -1294.946  -910.71   -880.545 -1233.509  -922.153  -805.37\n",
      " -1093.089  -899.186 -1318.008] -805.37 :6\n",
      "[-596.718 -856.859 -750.311 -572.801 -528.321 -689.804 -644.934 -582.189\n",
      " -596.585 -835.475] -528.321 :4\n",
      "[ -900.049 -1420.185  -985.652  -914.889  -880.24  -1067.893  -952.826\n",
      "  -932.624  -923.726 -1354.517] -880.24 :4\n",
      "[-1950.739 -1546.246 -1690.063 -1501.573 -2111.168 -1299.512 -1312.093\n",
      " -1546.498 -1568.501 -1501.506] -1299.512 :5\n",
      "[-1788.064 -1423.923 -1307.159 -1288.54  -1881.087 -1059.334 -1067.798\n",
      " -1570.144 -1422.052 -1395.177] -1059.334 :5\n",
      "[-1350.353 -1302.346 -1306.426 -1158.285 -1421.573 -1110.945 -1069.857\n",
      " -1214.284 -1143.783 -1350.813] -1069.857 :6\n",
      "[-1510.854 -1426.805 -1252.776 -1284.569 -1688.71  -1132.775 -1063.512\n",
      " -1434.869 -1341.793 -1389.185] -1063.512 :6\n",
      "[-1520.074 -1836.274 -1638.817 -1496.611 -1669.041 -1574.565 -1398.64\n",
      " -1278.041 -1466.767 -1684.246] -1278.041 :7\n",
      "[-1388.422 -1882.621 -1587.735 -1433.646 -1548.859 -1532.553 -1369.17\n",
      " -1144.543 -1410.828 -1770.009] -1144.543 :7\n",
      "[-1156.755 -1429.781 -1217.453 -1134.986 -1120.783 -1268.433 -1157.759\n",
      " -1174.938 -1104.507 -1521.014] -1104.507 :8\n",
      "[-1205.517 -1825.58  -1269.848 -1356.283 -1403.685 -1453.371 -1231.259\n",
      " -1332.831 -1164.811 -1808.001] -1164.811 :8\n",
      "[-1601.005 -1162.06  -1551.966 -1530.628 -1799.471 -1216.381 -1104.95\n",
      " -1141.227 -1388.874  -905.71 ] -905.71 :9\n",
      "[-1728.64  -1310.03  -1635.354 -1585.17  -2009.3   -1274.91  -1210.478\n",
      " -1360.039 -1566.689 -1046.89 ] -1046.89 :9\n",
      "\n",
      "Prediction for Testing DataSet:\n",
      "Label1:0\n",
      "Label2:0\n",
      "Label3:1\n",
      "Label4:1\n",
      "Label5:2\n",
      "Label6:2\n",
      "Label7:3\n",
      "Label8:3\n",
      "Label9:4\n",
      "Label10:4\n",
      "Label11:5\n",
      "Label12:5\n",
      "Label13:6\n",
      "Label14:6\n",
      "Label15:7\n",
      "Label16:7\n",
      "Label17:8\n",
      "Label18:8\n",
      "Label19:9\n",
      "Label20:9\n",
      "\n",
      "accuracy =90.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(\"Prediction started\")\n",
    "m_PredictionlabelList = []\n",
    "\n",
    "for i in range(0,len(m_testingsetfeatures)):\n",
    "    scores = []\n",
    "    for speechmodel in speechmodels:\n",
    "         scores.append(speechmodel.model.score(m_testingsetfeatures[i]))\n",
    "    id  = scores.index(max(scores))\n",
    "    m_PredictionlabelList.append(speechmodels[id].Class)\n",
    "    print(str(np.round(scores, 3)) + \" \" + str(max(np.round(scores, 3))) +\" \"+\":\"+ speechmodels[id].label)\n",
    "\n",
    "accuracy = 0.0\n",
    "count = 0\n",
    "print(\"\")\n",
    "print(\"Prediction for Testing DataSet:\")\n",
    "\n",
    "for i in range(0,len(m_testingsetlabels)):\n",
    "    print( \"Label\"+str(i+1)+\":\"+m_testingsetlabels[i])\n",
    "    if gmmhmmindexdict[m_testingsetlabels[i]] == m_PredictionlabelList[i]:\n",
    "       count = count+1\n",
    "\n",
    "accuracy = 100.0*count/float(len(m_testingsetlabels))\n",
    "\n",
    "print(\"\")\n",
    "print(\"accuracy =\"+str(accuracy))\n",
    "print(\"\")\n",
    "\n",
    "# end of testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2cc10f-ae74-4d39-bcdb-5863f58cb805",
   "metadata": {},
   "source": [
    "## End of Lab 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dd0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
